{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPClpRkGnHH1/DCfbxh4yuQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHxE3eQzrwYR","executionInfo":{"status":"ok","timestamp":1695382867708,"user_tz":-330,"elapsed":6863,"user":{"displayName":"Disura Hulangamuwa","userId":"01061465897456850363"}},"outputId":"994915ac-d7b2-487d-91f7-88f4425795aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mediapipe\n","  Downloading mediapipe-0.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.1.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.23.5)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n","Installing collected packages: sounddevice, mediapipe\n","Successfully installed mediapipe-0.10.5 sounddevice-0.4.6\n"]}],"source":["pip install mediapipe"]},{"cell_type":"code","source":["pip install opencv-python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J8n6GU7dsRzI","executionInfo":{"status":"ok","timestamp":1695382874749,"user_tz":-330,"elapsed":7049,"user":{"displayName":"Disura Hulangamuwa","userId":"01061465897456850363"}},"outputId":"9c0fc511-c7cc-490a-8e20-d95e209e3730"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"]}]},{"cell_type":"code","source":["import cv2\n","import mediapipe as mp\n","import numpy as np\n","mp_drawing = mp.solutions.drawing_utils\n","mp_pose = mp.solutions.pose"],"metadata":{"id":"GDXw_MW6sYY_","executionInfo":{"status":"ok","timestamp":1695382886984,"user_tz":-330,"elapsed":8210,"user":{"displayName":"Disura Hulangamuwa","userId":"01061465897456850363"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# cap = cv2.VideoCapture(0)\n","# while cap.isOpened():\n","#   ret,frame = cap.read()\n","#   cv2.imshow('Media Pipe Feed',frame)\n","\n","#   if cv2.waitKey(10) & 0xFF ==ord ('q'):\n","#     break\n","\n","# cap.release()\n","# cv2.destroyWindow(\"Media Pipe Feed\") #to close window press 'q'"],"metadata":{"id":"BcBSbJh1sbT-","executionInfo":{"status":"ok","timestamp":1695383253771,"user_tz":-330,"elapsed":688,"user":{"displayName":"Disura Hulangamuwa","userId":"01061465897456850363"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import cv2\n","\n","cap = cv2.VideoCapture(0)\n","\n","if not cap.isOpened():\n","    print(\"Error: Could not open the camera.\")\n","else:\n","    while True:\n","        ret, frame = cap.read()\n","\n","        if not ret:\n","            print(\"Error: Could not read a frame from the camera.\")\n","            break\n","\n","        cv2.imshow('Media Pipe Feed', frame)\n","\n","        if cv2.waitKey(10) & 0xFF == ord('q'):\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPocy_IMwIBj","executionInfo":{"status":"ok","timestamp":1695383867872,"user_tz":-330,"elapsed":477,"user":{"displayName":"Disura Hulangamuwa","userId":"01061465897456850363"}},"outputId":"88e92b7b-05fd-4497-a371-56c727819944"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: Could not open the camera.\n"]}]},{"cell_type":"code","source":["cap = cv2.VideoCapture(0)\n","## seting up mediapipe instance\n","with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose: #maintaining our confidence of 50%\n","    while cap.isOpened():\n","        ret,frame = cap.read() #frame = feed from webcaom\n","\n","        # recolor image to RGB\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        #image.flags.writeable = False\n","        image.flags.writeable = False\n","\n","        # make detection\n","        result = pose.process(image)\n","\n","        # recloring back to BGR\n","        #image.flags.writeable = False\n","        image.flags.writeable = True\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","\n","        # extract landmarks\n","        try:\n","            landmarks = result.pose_landmarks.landmark\n","            print(landmarks) #print landmarks\n","        except:\n","            pass\n","\n","        # render detection\n","        mp_drawing.draw_landmarks(image, result.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n","                                 mp_drawing.DrawingSpec(color=(245,117,66),thickness=2, circle_radius=2), # for joint\n","                                 mp_drawing.DrawingSpec(color=(245,66,230),thickness=2, circle_radius=2) # for connection\n","                                 ) #specifications for drawing a landmark\n","\n","        cv2.imshow('Media Pipe Feed',image)\n","\n","        if cv2.waitKey(10) & 0xFF ==ord ('q'):\n","            break\n","\n","    cap.release()\n","    cv2.destroyWindow(\"Media Pipe Feed\") #to close window press 'q'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210},"id":"JhKvwulOsnxr","executionInfo":{"status":"error","timestamp":1695383884213,"user_tz":-330,"elapsed":530,"user":{"displayName":"Disura Hulangamuwa","userId":"01061465897456850363"}},"outputId":"f085563b-6adc-4b0a-f379-a257f72b2424"},"execution_count":10,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-074961cae44a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Media Pipe Feed\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#to close window press 'q'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/highgui/src/window_QT.cpp:578: error: (-27:Null pointer) NULL guiReceiver (please create a window) in function 'cvDestroyWindow'\n"]}]},{"cell_type":"code","source":["landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n"],"metadata":{"id":"Txpl6C1Ns2q-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mp_pose.PoseLandmark.LEFT_SHOULDER.value"],"metadata":{"id":"jkp56tHts22z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Calculate Angles**"],"metadata":{"id":"t2i04fSys8y-"}},{"cell_type":"code","source":["def calculate_angle(a,b,c): # new function call calculate angle and pass 3 points\n","    a = np.array(a) # first point #these are the joints for calulating angles\n","    b = np.array(b) # mid point\n","    c = np.array(c) # end point\n","\n","    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0]) #cal radians and convert it to an angle ([y endpoint - y midpoint, x endpoint - x midpoint] - [y firstpoint - y midpoint, x firstpoint - x midpoint  ])\n","    angle = np.abs(radians*180.0/np.pi) #convert to angle\n","\n","    if angle > 180.0:\n","        angle = 360-angle\n","\n","        return angle"],"metadata":{"id":"qv_RTtm1s3DJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y] #grabing landmark for shoulder\n","elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n","wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"],"metadata":{"id":"4QCdiBFBtFUX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shoulder,elbow,wrist #show x,y values of left arm of the body"],"metadata":{"id":"k9P-da_GtH2B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["calculate_angle(shoulder,elbow,wrist) #calculate the angle"],"metadata":{"id":"BTdTCQvhtKdp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuple(np.multiply(elbow,[1280,720]).astype(int))"],"metadata":{"id":"bMGtG8AdtNBZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cap = cv2.VideoCapture(0)\n","## seting up mediapipe instance\n","with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose: #maintaining our confidence of 50%\n","    while cap.isOpened():\n","        ret,frame = cap.read() #frame = feed from webcaom\n","\n","        # recolor image to RGB\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        #image.flags.writeable = False\n","        image.flags.writeable = False\n","\n","        # make detection\n","        result = pose.process(image)\n","\n","        # recloring back to BGR\n","        #image.flags.writeable = False\n","        image.flags.writeable = True\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","\n","        # extract landmarks\n","        try:\n","            landmarks = result.pose_landmarks.landmark\n","\n","            #Getting coordinates\n","            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y] #grabing landmark for left arm side\n","            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n","            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n","\n","            #calculate angles\n","            angle=calculate_angle(shoulder,elbow,wrist) #calling calculate_angle function\n","\n","            #visulization\n","            cv2.putText(image, str(angle),\n","                            tuple(np.multiply(elbow[1280,720]).astype(int)), #elbow coordinate and mulity by dimensions of our webcam\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2,cv2.LINE_AA\n","                        ) #color size of the font\n","\n","\n","\n","        except:\n","            pass\n","\n","        # render detection\n","        mp_drawing.draw_landmarks(image, result.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n","                                 mp_drawing.DrawingSpec(color=(245,117,66),thickness=2, circle_radius=2), # for joint\n","                                 mp_drawing.DrawingSpec(color=(245,66,230),thickness=2, circle_radius=2) # for connection\n","                                 ) #specifications for drawing a landmark\n","\n","\n","        cv2.imshow('Media Pipe Feed',image)\n","\n","\n","        if cv2.waitKey(10) & 0xFF ==ord ('q'):\n","            break\n","\n","    cap.release()\n","    cv2.destroyWindow(\"Media Pipe Feed\") #to close window press 'q'"],"metadata":{"id":"-d5h61LCtToA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cap = cv2.VideoCapture(0)\n","\n","#curl counter variables\n","counter = 0\n","stage = None\n","\n","## seting up mediapipe instance\n","with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose: #maintaining our confidence of 50%\n","    while cap.isOpened():\n","        ret,frame = cap.read() #frame = feed from webcaom\n","\n","        # recolor image to RGB\n","        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        #image.flags.writeable = False\n","        image.flags.writeable = False\n","\n","        # make detection\n","        result = pose.process(image)\n","\n","        # recloring back to BGR\n","        #image.flags.writeable = False\n","        image.flags.writeable = True\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","\n","        # extract landmarks\n","        try:\n","            landmarks = result.pose_landmarks.landmark\n","\n","            #Getting coordinates\n","            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y] #grabing landmark for left arm side\n","            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n","            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n","\n","            #calculate angles\n","            angle=calculate_angle(shoulder,elbow,wrist) #calling calculate_angle function\n","\n","            #visulization\n","            cv2.putText(image, str(angle),\n","                            tuple(np.multiply(elbow[1280,720]).astype(int)), #elbow coordinate and mulity by dimensions of our webcam\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2,cv2.LINE_AA\n","                        ) #color size of the font\n","\n","\n","            #Curl counter Logic\n","            if angle > 160:\n","                stage = \"down\"\n","            if angle < 30 and stage =='down':\n","                stage = \"up\"\n","                counter +=1\n","                print(counter)\n","\n","\n","\n","        except:\n","            pass\n","\n","            #Render curl counter\n","            #steup status box\n","            cv2.rectangle(image, (0,0), (225,73), (245,117,16), -1)\n","\n","            # Rep data\n","            cv2.putText(image, 'REPS', (15,12),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1,cv2.LINE_AA)\n","            cv2.putText(image, str(counter),\n","                        (10,60),\n","                       cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2,cv2.LINE_AA)\n","\n","\n","            # Stage data\n","            cv2.putText(image, 'STAGE', (65,12),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1,cv2.LINE_AA)\n","            cv2.putText(image, str(counter),\n","                        (60,60),\n","                       cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2,cv2.LINE_AA)\n","\n","        # render detection\n","        mp_drawing.draw_landmarks(image, result.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n","                                 mp_drawing.DrawingSpec(color=(245,117,66),thickness=2, circle_radius=2), # for joint\n","                                 mp_drawing.DrawingSpec(color=(245,66,230),thickness=2, circle_radius=2) # for connection\n","                                 ) #specifications for drawing a landmark\n","\n","\n","        cv2.imshow('Media Pipe Feed',image)\n","\n","\n","        if cv2.waitKey(10) & 0xFF ==ord ('q'):\n","            break\n","\n","    cap.release()\n","    cv2.destroyWindow(\"Media Pipe Feed\") #to close window press 'q'"],"metadata":{"id":"iL0QTE5UtaF9"},"execution_count":null,"outputs":[]}]}